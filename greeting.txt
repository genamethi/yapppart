Hello new initiate. We're studying a particular number theoretic question.
It falls mostly within the theory of Diophantine equations (so, integer solutions to polynomial equations).

The main question is:

Given n prime, how many ways can we partition n such that:

n = p^j + q^k for p, q prime and j, k >= 1.

Let's simplify this with an observation.

Even/Odd Number Parity:

Assume p = q.

This would mean that n = p^{min(j, k)}(p^{max(j,k)/min(j,k)} + 1) which means p^{min(j, k)} | n.

This means that n is even, which is only true of n = 2. So, for odd primes we can assume WLOG
that p < q.

Furthermore, by parity we know that two odd numbers added together are even.

Therefore, p = 2 for every n, when p < q.

We have the following directory structure:

 tree -L 4 . (from Cursor root directory (workspace))
.
├── giotto-ph
... elided for clarity ... external lib (see pyproject.toml)
... we use this for persistent homology ...
├── giotto-tda
... elided for clarity ... external lib (see pyproject.toml)
... more general Topological Data Analysis ...
├── pixi.lock
├── pyproject.toml # I use pyproject.toml instead of pixi.toml, despite using pixi.
├── pytest.ini # See the ignore list, it needs work, but it can wait.
├── setup.py # Build configuration and Cython support
├── sample
│   └── viz
│       ├── prime_partitions_count_plot.html
│       └── zero_partitions_frequency_by_digits.csv
├── src #Standard src directory structure.
│   ├── datarunner.sh # This isn't quite up to date, but should work. (not urgent)
│   └── pppart # This is the main package.
│       ├── chain_complex.py # a particular implementation of 1 to 0 chain complexes. Pretty neat. We want to get a handle on these coefficients and analyze the cohomological structure.
│       ├── core.py        # This generates the data. It's the most sophicated part in terms of optimizations and architecture.
│       ├── data
│       │   ├── partition_data.csv # Main data file (used with --resume)
│       │   ├── tmp/ # Temporary output directory (default for new runs)
│       │   └── backups/ # Backup directory for data files
│       ├── filters.py  # Sheaf-theoretic operations discovered through computational exploration - pullbacks, stalks, and basis constructions for studying the topology of prime representations.
│       ├── __init__.py
│       ├── __main__.py # This is the main entry point.
│       ├── __pycache__
...
│       ├── spaces.py # Our metric space classes important for our adjacency matrix.
│       ├── stats.py # Some basic stats stuffs, random matrices.
│       ├── tda.py # Our TDA functions (really not a lot, but this is where we will implement our persistent homology).
│       ├── utils.py    # File I/O and other utilities.
│       ├── viz # This is the visualization package.
│       │   ├── __init__.py
│       │   ├── viz_base_pairs.py   #Delay at the moment
│       │   ├── viz_batch_rate.py   #Delay at the moment, but analyzes the batch rate via reading the tdqm output via datarunner.csv. The rate of generation of batches appears to have a zeta distribution, but I could be imagining things
│       │   ├── viz_ppp_counts.py  #Updated to use numpy/Altair instead of pandas/matplotlib. Gives us basic visualization/tables for prime power partitions of n. The counts for how many each n has. Note we use n, 0, 0, 0, 0 when there are 0 partitions. These I think are important, but eventually we care about the complement.
│       │   └── viz_tda_stats.py    #I can't remember this, but it's new and probably going to be relevant immmediately.
│       └── zero_analysis.py    # Scaffold for KDE→symbolic fitting pipeline. Functions for density estimation, model comparison, spectral analysis, and closed-form PDF discovery for zero-partition primes.
├── tests   # Tests now include comprehensive contract testing for zero analysis functions and numpy/Altair visualization validation.
│   ├── __pycache__
...
│   ├── test_csv_output.py
│   ├── testgen.sh
│   ├── test-output.xml
│   ├── test_summary_table.py
│   ├── test_utils_critical.py
│   ├── test_version_based.py
│   ├── test_visualization_contract.py
│   └── test_zero_analysis_contracts.py
└── vizquiz.txt # This is really important! I'm developing a challenge for an LLM. Or a series of challenges. So this is part of building prompts.

Note the comment on the viz_ppp_counts.py line: We use n, 0, 0, 0, 0 when there are 0 partitions.

This is part of our mentality in several parts of the package. zero_analysis is one, the construction of chain complexes is another. But as we get to large N, it
doesn't matter as much.

Our analysis has revealed interesting patterns: zero-partition rates increase from ~7% for 3-digit primes to ~15% for 6-digit primes, suggesting a phase transition in representable vs non-representable primes as n grows.

So, yeah I use pixi and SageMath. Wherever possible we use vectorized methods. No pandas.
I don't like loops for the most part.
This is for pure math research, so we do care about precision in most cases except for
some cases like with PH (or can we?)

q-adics are relevant because of the q column, but we group by q (see the qSpaceClass Which should be renamed tbh)
See memories about my feelings on variable names.

Configuration flows: pyproject.toml (source of truth) → utils.py → modules. Data output behavior: default runs create timestamped files in src/pppart/data/tmp/, resume runs append to src/pppart/data/partition_data.csv.
